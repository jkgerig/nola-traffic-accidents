{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('../../data/processed/all_samples.pickle')\n",
    "data['datetime'] = pd.to_datetime(data.date)\n",
    "data['day'] = data.datetime.dt.weekday_name\n",
    "data = pd.get_dummies(data, prefix='day', columns=['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['hour',\n",
    "            'daylight_yn',\n",
    "            'holiday_yn',\n",
    "            'rush_hour_yn',\n",
    "            'temp',\n",
    "            'wind_speed',\n",
    "            'precipitation',\n",
    "            'road_length',\n",
    "            'class_freeway',\n",
    "            'class_local',\n",
    "            'class_major',\n",
    "            'class_other',\n",
    "            'class_unimproved',\n",
    "            'day_Monday',\n",
    "            'day_Tuesday',\n",
    "            'day_Wednesday',\n",
    "            'day_Thursday',\n",
    "            'day_Friday',\n",
    "            'day_Saturday',\n",
    "            'day_Sunday']\n",
    "\n",
    "labels = 'accident_yn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[features]\n",
    "y = data[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    accuracy = 100 * metrics.accuracy_score(test_labels, predictions)\n",
    "    precision = 100 * metrics.precision_score(test_labels, predictions)\n",
    "    recall = 100 * metrics.recall_score(test_labels, predictions)\n",
    "    f1 = metrics.f1_score(test_labels, predictions)\n",
    "    roc_auc = metrics.roc_auc_score(test_labels, predictions)\n",
    "\n",
    "    print('Model Performance')\n",
    "    print('Accuracy:\\t{:0.2f}%'.format(accuracy))\n",
    "    print('Precision:\\t{:0.2f}%'.format(precision))\n",
    "    print('Recall:\\t\\t{:0.2f}%'.format(recall))\n",
    "    print('F1 Score:\\t{:0.2f}'.format(f1))\n",
    "    print('ROC AUC:\\t{:0.2f}'.format(roc_auc))\n",
    "\n",
    "    return (accuracy, precision, recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_performance = evaluate(base_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed:   25.6s remaining:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   31.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [5, 7, 10]}, pre_dispatch='2*n_jobs',\n",
       "       refit=False, return_train_score='warn',\n",
       "       scoring=['accuracy', 'precision', 'recall'], verbose=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_n_estimators = {'n_estimators': [5, 7, 10]}\n",
    "scores = ['accuracy', 'precision', 'recall']\n",
    "\n",
    "# GridSearch on n_estimators\n",
    "search_n_estimators = GridSearchCV(rf, \n",
    "                                   param_grid=grid_n_estimators, \n",
    "                                   n_jobs=-1, \n",
    "                                   cv=3, \n",
    "                                   scoring=scores, \n",
    "                                   refit=False,\n",
    "                                   verbose=2)\n",
    "\n",
    "search_n_estimators.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 7, 10]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(search_n_estimators.cv_results_['param_n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_performance = evaluate(best_random, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improvement_accuracy = 100 * (random_performance[0] - base_performance[0]) / base_performance[0]\n",
    "improvement_precision = 100 * (random_performance[1] - base_performance[1]) / base_performance[1]\n",
    "improvement_recall = 100 * (random_performance[2] - base_performance[2]) / base_performance[2]\n",
    "\n",
    "print('Accuracy Improvement:\\t{:0.2f}%.'.format(improvement_accuracy))\n",
    "print('Precision Improvement:\\t{:0.2f}%.'.format(improvement_precision))\n",
    "print('Recall Improvement:\\t{:0.2f}%.'.format(improvement_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': 1,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "pprint(base_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_default = None\n",
    "min_samples_leaf_default = 1\n",
    "min_samples_split_default = 2\n",
    "n_estimators_default = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_range: [10, 32, 55, 77, 100, None]\n",
    "min_samples_leaf_range: [1, 2, 4, 6, 7, 10]\n",
    "min_samples_split_range: [2, 5, 8, 12]\n",
    "n_estimators_range: [50, 75, 100, 125, 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(model, param = 'n_estimators', name = 'Num Trees'):\n",
    "    param_name = 'param_%s' % param\n",
    "\n",
    "    # Extract information from the cross validation model\n",
    "    train_scores = model.cv_results_['mean_train_score']\n",
    "    test_scores = model.cv_results_['mean_test_score']\n",
    "    train_time = model.cv_results_['mean_fit_time']\n",
    "    param_values = list(model.cv_results_[param_name])\n",
    "    \n",
    "    # Plot the scores over the parameter\n",
    "    plt.subplots(1, 2, figsize=(10, 6))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(param_values, train_scores, 'bo-', label = 'train')\n",
    "    plt.plot(param_values, test_scores, 'go-', label = 'test')\n",
    "    plt.ylim(ymin = -10, ymax = 0)\n",
    "    plt.legend()\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel('Neg Mean Absolute Error')\n",
    "    plt.title('Score vs %s' % name)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.plot(param_values, train_time, 'ro-')\n",
    "    plt.ylim(ymin = 0.0, ymax = 2.0)\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel('Train Time (sec)')\n",
    "    plt.title('Training Time vs %s' % name)\n",
    "    \n",
    "    \n",
    "    plt.tight_layout(pad = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
